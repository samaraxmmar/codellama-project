{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CodeLlama Fine-tuning Exploration\n",
    "\n",
    "This notebook demonstrates how to explore the dataset and experiment with the fine-tuned CodeLlama model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset(\"samaxr/code-summary-java\")\n",
    "print(f\"Dataset splits: {dataset.keys()}\")\n",
    "print(f\"Training examples: {len(dataset['train'])}\")\n",
    "print(f\"Validation examples: {len(dataset['validation'])}\")\n",
    "print(f\"Test examples: {len(dataset['test'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine a few examples\n",
    "for i in range(3):\n",
    "    example = dataset['train'][i]\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"Code: {example['code'][:200]}...\")\n",
    "    print(f\"Summary: {example['summary']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze code and summary lengths\n",
    "train_data = dataset['train']\n",
    "code_lengths = [len(example['code']) for example in train_data]\n",
    "summary_lengths = [len(example['summary']) for example in train_data]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(code_lengths, bins=50, alpha=0.7)\n",
    "plt.title('Distribution of Code Lengths')\n",
    "plt.xlabel('Code Length (characters)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(summary_lengths, bins=50, alpha=0.7)\n",
    "plt.title('Distribution of Summary Lengths')\n",
    "plt.xlabel('Summary Length (characters)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Loading and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the base CodeLlama model for comparison\n",
    "model_name = \"codellama/CodeLlama-7b-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test code generation with base model\n",
    "def generate_code(model, tokenizer, prompt, max_length=100):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(\n",
    "        inputs.input_ids,\n",
    "        max_length=max_length,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Test with a simple prompt\n",
    "test_prompt = \"public class Calculator {\"\n",
    "generated = generate_code(base_model, tokenizer, test_prompt)\n",
    "print(f\"Prompt: {test_prompt}\")\n",
    "print(f\"Generated: {generated}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for easier analysis\n",
    "df = pd.DataFrame({\n",
    "    'code': [example['code'] for example in train_data[:1000]],  # Sample for performance\n",
    "    'summary': [example['summary'] for example in train_data[:1000]]\n",
    "})\n",
    "\n",
    "df['code_length'] = df['code'].str.len()\n",
    "df['summary_length'] = df['summary'].str.len()\n",
    "df['code_lines'] = df['code'].str.count('\\n') + 1\n",
    "\n",
    "print(\"Dataset Statistics:\")\n",
    "print(df[['code_length', 'summary_length', 'code_lines']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "correlation_matrix = df[['code_length', 'summary_length', 'code_lines']].corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Matrix: Code and Summary Metrics')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze tokenization\n",
    "sample_codes = [example['code'] for example in train_data[:100]]\n",
    "sample_summaries = [example['summary'] for example in train_data[:100]]\n",
    "\n",
    "# Tokenize samples\n",
    "code_tokens = [len(tokenizer.encode(code)) for code in sample_codes]\n",
    "summary_tokens = [len(tokenizer.encode(summary)) for summary in sample_summaries]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(code_tokens, bins=20, alpha=0.7)\n",
    "plt.title('Distribution of Code Token Counts')\n",
    "plt.xlabel('Number of Tokens')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(summary_tokens, bins=20, alpha=0.7)\n",
    "plt.title('Distribution of Summary Token Counts')\n",
    "plt.xlabel('Number of Tokens')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average code tokens: {sum(code_tokens)/len(code_tokens):.2f}\")\n",
    "print(f\"Average summary tokens: {sum(summary_tokens)/len(summary_tokens):.2f}\")\n",
    "print(f\"Max code tokens: {max(code_tokens)}\")\n",
    "print(f\"Max summary tokens: {max(summary_tokens)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

